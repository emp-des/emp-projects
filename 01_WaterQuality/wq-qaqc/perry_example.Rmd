|                                                                                        |
|------------------------------------------------------------------------|
| Title: Monthly D-WQ Review and Formatting (Prelim)                                     |
| Authors: Sarah Perry & Morgan Battey                                                   |
| Description: preliminary practice version of reusable code to format monthly D-WQ data |
| Date Modified: 6/19/23                                                                 |

# Intro

Last time, we ended with a major issue: we didn't know how to grab all the rows below a certain one, and Google wasn't helping. We couldn't figure out a way to write a logical statement to grab the data we want.

Before looking for a solution, let's take a step back and talk about some basic tenants of coding.

Coding is essentially a giant puzzle (I want to take this input Excel file and output a different one; how do I do that?). This question is made up of smaller puzzles (how do I create an Excel sheet with only blank data?), which, in turn, has even more puzzles (how do I subset blanks in a data frame?) Etc. etc.

### Tenents 1
Therefore, it's best to approach every step of script writing as solving a small puzzle. Three things to keep in mind:

-   You want the logic of your code *to be explainable by your dataset*. This helps with readability, reproducibility, and catching errors.
    -   An example: I have a data frame where column `Fruit` is fruits and column `Color` is the common color associated with them. If I subset `df[2,2]`, do you know what color I get? What if I subset by `df %>% subset(fruit == 'banana')`?
-   For every question, ask yourself: is my solution **mutually exclusive**? Ie., will the output always be the product I want, and nothing else?

- If you find yourself writing code that violates these two tenants, while it might still work, that might indicate it's time to take a step back and re-evaluate how you're approaching the puzzle.

These tenents work no matter sort of coding your doing, but is especially applicable when working with data frames. Let's do a worked example based on our data.

## Thought Experiment

Let's look at the data again from where we left off.

```{r message = FALSE}
# import packages
library(tidyverse)
library(readxl)

# import data
df_raw <- read_excel('01_WaterQuality/wq-qaqc/raw-data/test-import.xlsx', skip = 1) # skip initial row
df_raw <- df_raw %>% select(-contains('...')) # remove columns containing '...'

df_test <- df_raw %>% subset(`Sample Type` == 'Blank; Equipment') # filter by Blanks
```

We know we can't easily go back and subset by "<<Field Results>>". What else could we do?

Well, we could use the logic "Chla is always NA for field data, so if we use the logic `!is.na(df$Chla)`, then we will only get lab results back!
However, is this actually **mutually exclusive**? What if the Chla samples were ruined one day, so no result was entered? In that case, by excluding `is.na(Chla)`, we could be excluding lab data. So the answer is **no**.

Well, taking that a step further, every lab column is NA for field data. So how about we use the logic `is.na(<all lab columns>)`? Is that mutually exclusive?
There is the possibility that a catastrophic failure happened during sampling (maybe all our bottles broke), and in that case, all the lab entries would be NA for lab data. Therefore, this logic solution is still not mutually exclusive. However, events like those are incredibly rare, so can we still use this logic?

### Tenents 2
This leads to our next set of tenents. If your solution is *almost* completely mutually exclusive (ME), ask yourself:

- are there checks we can put in place to flag when a non-ME event occurs?

- if the code flags that they're not ME, this is useful information, because We now have 100% certainty that the flagged data is 1) not ME and 2) not what we want. Given this information, is there a further differentiator we could use to distinguish them?

- repeat this process until satisfied with the level of ME

While these tenants are important, and very useful, once you start going through this loop, you run the risk of writing code that is too complex, messy, and not based on the dataset itself. So, before diving into this, let's take a step back again and re-evaluate.

### Re-evaluate
Our core puzzle is we want a way to subset field data. It still would be easiest if we could just grab all the data below a certain row; logically, this looks something like `df %>% subset(<a differentiator> >= <the value @ the Field Results row>)`. We couldn't do this solely by filtering, because the output: 
```{r}
print(df_raw %>% subset(`Station Name` == '<<<Field Results>>>'))
```
doesn't give us a differentiator that we could use to subset the rows below it. We need some sort of numerical list...like an index.... Then the logic `df %>% subset(<row> >= <index number>)` would work. Let's Google if adding an index is possible:

https://stackoverflow.com/questions/23518605/add-an-index-numeric-id-column-to-large-data-frame

(I looked up "read_csv skip until condition met tidyverse")

```{r}
df_test <- df_raw %>%
  mutate(id = row_number()) %>% # add index column
  relocate(id, .before = `Station Name`) # relocate to before Station Name, which we're 99% certain will be the first col
  

print(df_test %>% subset(`Station Name` == '<<<Field Results>>>'))
```
Nice! However, this doesn't mean the data is sequentially listed as we see it in the viewer. There are fancy ways to check this. However, for now, we know that the next row should be the column names; so let's subset by that index value and check:

```{r}
df_test[42,]
```
Yup, that's what we expected!

While a little messy, we do have logic now that
- is fairly readable (especially with comments) and mostly based on data
- is mutually exclusive

Now, all we need to do is filter the data to remove columns before the ones we want. However, while this time I know the number (41), I don't want to hard code that. So, first, let's make the row ID for the field data column a *variable*

```{r}
vari_id <- df_test %>% subset(`Station Name` == '<<<Field Results>>>', select = c(id))
```

```{r}
ty
```


```{r}
df_test2 <- df_test %>% subset(id >= )